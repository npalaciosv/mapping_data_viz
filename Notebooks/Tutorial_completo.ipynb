{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Mapeando datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Apuntar\n",
    "\n",
    "üóíÔ∏è **Observaciones:**\n",
    "\n",
    "‚ö†Ô∏è **Alertas:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Importamos las respectivas librer√≠as**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import folium\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Descomprimimos los archivos correspondientes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Creamos una variable path que nos ayude a indentificar donde estan todos los archivos zip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = '/home/npalaciosv/Catedra/Geoanalitycs/src/Data/Raw/'\n",
    "silver_path = '/home/npalaciosv/Catedra/Geoanalitycs/src/Data/Silver/'\n",
    "\n",
    "data_files = Path(raw_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Necesitamos recorrer la carpeta ya que habra mas de un archivo zip, luego vamos a descomprimirlos, almacenarlos en un dataframe y juntarlos todos. Usamos la libreria Path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in data_files.rglob('*'):\n",
    "    new_name = file.name.replace(\" \",\"\").replace(\"_\",\"\")\n",
    "    new_path = file.with_name(new_name)\n",
    "    file.rename(new_path)\n",
    "    with zipfile.ZipFile(f'{raw_path+file.name}','r') as extraction:\n",
    "        extraction.extractall(silver_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Eliminamos los archivos que tienen un formato diferente a csv.\n",
    "\n",
    "üóíÔ∏è **Observaciones:** La librer√≠a path tambien es √∫til en este caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_files = Path(silver_path)\n",
    "for file in silver_files.iterdir():\n",
    "    # Verificar si es un archivo y no termina en '.csv'\n",
    "    if file.is_file() and file.suffix != '.csv':\n",
    "        # Eliminar el archivo\n",
    "        file.unlink()\n",
    "        print(f'Eliminado: {file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Alertas:** Algunos archivos se descomprimen dentro de una carpeta, por lo tanto nos toca moverlos hacia el directorio Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in silver_files.iterdir():\n",
    "    if file.is_file():\n",
    "        pass\n",
    "    else:\n",
    "        subfolder = silver_files.joinpath(file.name)\n",
    "        for subfile in subfolder.glob('*'):\n",
    "            if subfile.suffix == '.csv':\n",
    "                subfile.replace(silver_path+\"/\"+subfile.name)\n",
    "                print(f'Archivo: {subfile.name} movido exitosamente')\n",
    "\n",
    "        shutil.rmtree(subfolder)\n",
    "        print(f'Carpeta: {subfolder.name} elminada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Unificamos la informacion que necesitamos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Creamos un dataframe vacio y ahi concatenamos toda la informacion que necesitamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Alertas:** Es posible que las bases de datos no tengan exactamente las mismas columnas. Previamente preparamos un diccionario que nos va a ayudar a normalizar los nombres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_ajustadas = {\n",
    "    'Fuente':'Mayorista',\n",
    "    'FechaEncuesta':'Fecha',\n",
    "    'Fecha':'Fecha',\n",
    "    'Cod. Depto Proc.':'Codigo departamento',\n",
    "    'Cod. Municipio Proc.':'Codigo municipio',\n",
    "    'Departamento Proc.':'Departamento',\n",
    "    'Municipio Proc.':'Municipio',\n",
    "    'Grupo':'Grupo',\n",
    "    'Ali':'Alimento',\n",
    "    'Cant Kg':'Cant Kg',\n",
    "    'C√≥digo Departamento':'Codigo departamento',\n",
    "    ' C√≥digo Municipio ':'Codigo municipio',\n",
    "    'Alimento':'Alimento',\n",
    "    'Cuidad, Mercado Mayorista':'Mayorista',\n",
    "    'Origen':'Origen',\n",
    "    'Unnamed: 9':'Unnamed: 9',\n",
    "    'Unnamed: 10':'Unnamed: 10',\n",
    "    'Codigo CPC':'Codigo CPC'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Ajustamos los nombres de todos los archivos de acuerdo al diccionario que acabamos de definir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in silver_files.iterdir():\n",
    "    df_temp = pd.read_csv(file, encoding='unicode_escape', sep=\";\")\n",
    "    df_temp['Origen'] = file.name\n",
    "    for column in df_temp.columns:\n",
    "        df_temp.rename(columns={column: columnas_ajustadas[column]}, inplace=True)\n",
    "    df =pd.concat([df,df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Eliminamos las columnas que no vamos a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 9','Unnamed: 10','Codigo CPC'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Homologamos dentro de la columna *\"Fuente\"* a *\"Cali, Santa Elena\"* por *\"Cali, Santa Helena\"*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Mayorista\"] == \"Cali, Santa Elena\", \"Mayorista\"] = \"Cali, Santa Helena\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Enviamos la informacion a un archivo csv para ver como se est√° juntando el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_path = '/home/npalaciosv/Catedra/Geoanalitycs/src/Database/geo.db'\n",
    "conn = sqlite3.connect(database_path)\n",
    "df.to_sql('Fact', con=conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moviendo_db(database_path, user_path):\n",
    "    shutil.move(database_path, user_path)\n",
    "    print(f'Archivo movido a {user_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_path = '/mnt/d/Classes/Data visualization/Mapping data/Database/geo.db'\n",
    "\n",
    "moviendo_db(database_path=database_path,user_path=user_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Iniciamos con la construccion de los mapas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.1 Establecemos las coordenadas de los centros mayoristas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Primero importamos las coordenadas de cada uno de los centros de acopia que se mencionan en la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordenadas_path = \"/home/npalaciosv/Catedra/Geoanalitycs/src/Data/Static/Coordenadas.csv\"\n",
    "df_coor = pd.read_csv(coordenadas_path,sep=\";\",encoding='utf-8')\n",
    "\n",
    "conn = sqlite3.connect(user_path)\n",
    "df_coor.to_sql('Coordenadas_mayoristas', con=conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Creamos el objeto mapa utilizando la libreria folium. Especificamos un punto central para que aparezca el mapa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = folium.Map(location=[4.922860659232988, -74.02580517889908], zoom_start=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Llamamos el icono de una plaza de mercado que escogimos para ponerlo como icono de marcacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "icon_path = '/home/npalaciosv/Catedra/Geoanalitycs/src/Icons/Mayorista.png'\n",
    "\n",
    "#\n",
    "lat = df_coor['Latitud'].to_list()\n",
    "lon = df_coor['Longitud'].to_list()\n",
    "fuente = df_coor['Mayorista'].to_list()\n",
    "coordenadas = list(zip(lat,lon,fuente))\n",
    "\n",
    "#\n",
    "for lat,lon,fuente in coordenadas:\n",
    "    folium.Marker(\n",
    "        [lat,lon],\n",
    "        popup=f'{fuente}',\n",
    "        icon=folium.CustomIcon(icon_image=icon_path,icon_size=(20,20))\n",
    "    ).add_to(map)\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.2 Establecemos las coordenadas de los municipios abastecedor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "halo = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoanalitics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
