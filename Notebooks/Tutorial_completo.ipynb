{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Mapeando datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Apuntar\n",
    "\n",
    "üóíÔ∏è **Observaciones:**\n",
    "\n",
    "‚ö†Ô∏è **Alertas:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Importamos las respectivas librer√≠as**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import folium\n",
    "import sqlite3\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Descomprimimos los archivos correspondientes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Creamos una variable path que nos ayude a indentificar donde estan todos los archivos zip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = '/home/npalaciosv/Catedra/Geoanalitycs/src/Data/Raw/'\n",
    "silver_path = '/home/npalaciosv/Catedra/Geoanalitycs/src/Data/Silver/'\n",
    "\n",
    "data_files = Path(raw_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Necesitamos recorrer la carpeta ya que habra mas de un archivo zip, luego vamos a descomprimirlos, almacenarlos en un dataframe y juntarlos todos. Usamos la libreria Path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in data_files.rglob('*'):\n",
    "    new_name = file.name.replace(\" \",\"\").replace(\"_\",\"\")\n",
    "    new_path = file.with_name(new_name)\n",
    "    file.rename(new_path)\n",
    "    with zipfile.ZipFile(f'{raw_path+file.name}','r') as extraction:\n",
    "        extraction.extractall(silver_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Eliminamos los archivos que tienen un formato diferente a csv.\n",
    "\n",
    "üóíÔ∏è **Observaciones:** La librer√≠a path tambien es √∫til en este caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliminado: /home/npalaciosv/Catedra/Geoanalitycs/src/Data/Silver/2020_SemII.dta\n",
      "Eliminado: /home/npalaciosv/Catedra/Geoanalitycs/src/Data/Silver/2019_SemII.dta\n",
      "Eliminado: /home/npalaciosv/Catedra/Geoanalitycs/src/Data/Silver/2021 ( I Semestre).dta\n",
      "Eliminado: /home/npalaciosv/Catedra/Geoanalitycs/src/Data/Silver/2019_SemII.sav\n",
      "Eliminado: /home/npalaciosv/Catedra/Geoanalitycs/src/Data/Silver/2019_SemI.dta\n",
      "Eliminado: /home/npalaciosv/Catedra/Geoanalitycs/src/Data/Silver/2018_SemI.sav\n",
      "Eliminado: /home/npalaciosv/Catedra/Geoanalitycs/src/Data/Silver/2018_SemII.dta\n",
      "Eliminado: /home/npalaciosv/Catedra/Geoanalitycs/src/Data/Silver/2020_SemI.dta\n",
      "Eliminado: /home/npalaciosv/Catedra/Geoanalitycs/src/Data/Silver/2020_SemII.sav\n",
      "Eliminado: /home/npalaciosv/Catedra/Geoanalitycs/src/Data/Silver/2019_SemI.sav\n",
      "Eliminado: /home/npalaciosv/Catedra/Geoanalitycs/src/Data/Silver/2018_SemII.sav\n",
      "Eliminado: /home/npalaciosv/Catedra/Geoanalitycs/src/Data/Silver/2021 ( I Semestre).sav\n",
      "Eliminado: /home/npalaciosv/Catedra/Geoanalitycs/src/Data/Silver/2022(II Semestre).dta\n",
      "Eliminado: /home/npalaciosv/Catedra/Geoanalitycs/src/Data/Silver/2022(II Semestre).sav\n",
      "Eliminado: /home/npalaciosv/Catedra/Geoanalitycs/src/Data/Silver/2018_SemI.dta\n",
      "Eliminado: /home/npalaciosv/Catedra/Geoanalitycs/src/Data/Silver/2020_SemI.sav\n"
     ]
    }
   ],
   "source": [
    "silver_files = Path(silver_path)\n",
    "for file in silver_files.iterdir():\n",
    "    # Verificar si es un archivo y no termina en '.csv'\n",
    "    if file.is_file() and file.suffix != '.csv':\n",
    "        # Eliminar el archivo\n",
    "        file.unlink()\n",
    "        print(f'Eliminado: {file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Alertas:** Algunos archivos se descomprimen dentro de una carpeta, por lo tanto nos toca moverlos hacia el directorio Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: 2021(II Semestre).csv movido exitosamente\n",
      "Carpeta: 2021 (II.semestre) elminada\n",
      "Archivo: SIPSA_A_Isem2022.csv movido exitosamente\n",
      "Carpeta: 2022 ( I Semestre ) elminada\n",
      "Archivo: SIPSA_A Isem2024.csv movido exitosamente\n",
      "Carpeta: 2024 ( I Semestre ) elminada\n",
      "Archivo: SIPSA_A_IIsem2023.csv movido exitosamente\n",
      "Carpeta: 2023 ( II Semestre ) elminada\n",
      "Archivo: SIPSA_A_Isem2023.csv movido exitosamente\n",
      "Carpeta: SIPSA_A_Isem2023 elminada\n"
     ]
    }
   ],
   "source": [
    "for file in silver_files.iterdir():\n",
    "    if file.is_file():\n",
    "        pass\n",
    "    else:\n",
    "        subfolder = silver_files.joinpath(file.name)\n",
    "        for subfile in subfolder.glob('*'):\n",
    "            if subfile.suffix == '.csv':\n",
    "                subfile.replace(silver_path+\"/\"+subfile.name)\n",
    "                print(f'Archivo: {subfile.name} movido exitosamente')\n",
    "\n",
    "        shutil.rmtree(subfolder)\n",
    "        print(f'Carpeta: {subfolder.name} elminada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Unificamos la informacion que necesitamos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Creamos un dataframe vacio y ahi concatenamos toda la informacion que necesitamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Alertas:** Es posible que las bases de datos no tengan exactamente las mismas columnas. Previamente preparamos un diccionario que nos va a ayudar a normalizar los nombres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_ajustadas = {\n",
    "    'Fuente':'Mayorista',\n",
    "    'FechaEncuesta':'Fecha',\n",
    "    'Fecha':'Fecha',\n",
    "    'Cod. Depto Proc.':'Codigo_departamento',\n",
    "    'Cod. Municipio Proc.':'Codigo_municipio',\n",
    "    'Departamento Proc.':'Departamento',\n",
    "    'Municipio Proc.':'Municipio',\n",
    "    'Grupo':'Grupo',\n",
    "    'Ali':'Alimento',\n",
    "    'Cant Kg':'Cant_Kg',\n",
    "    'C√≥digo Departamento':'Codigo_departamento',\n",
    "    ' C√≥digo Municipio ':'Codigo_municipio',\n",
    "    'Alimento':'Alimento',\n",
    "    'Cuidad, Mercado Mayorista':'Mayorista',\n",
    "    'Origen':'Origen',\n",
    "    'Unnamed: 9':'Unnamed: 9',\n",
    "    'Unnamed: 10':'Unnamed: 10',\n",
    "    'Codigo CPC':'Codigo CPC'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Ajustamos los nombres de todos los archivos de acuerdo al diccionario que acabamos de definir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_217208/1997498870.py:2: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_temp = pd.read_csv(file, encoding='unicode_escape', sep=\";\")\n"
     ]
    }
   ],
   "source": [
    "for file in silver_files.iterdir():\n",
    "    df_temp = pd.read_csv(file, encoding='unicode_escape', sep=\";\")\n",
    "    df_temp['Origen'] = file.name\n",
    "    for column in df_temp.columns:\n",
    "        df_temp.rename(columns={column: columnas_ajustadas[column]}, inplace=True)\n",
    "    df =pd.concat([df,df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Eliminamos las columnas que no vamos a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 9','Unnamed: 10','Codigo CPC'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Homologamos dentro de la columna *\"Fuente\"* a *\"Cali, Santa Elena\"* por *\"Cali, Santa Helena\"*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Mayorista\"] == \"Cali, Santa Elena\", \"Mayorista\"] = \"Cali, Santa Helena\"\n",
    "df['Codigo_municipio'] = df['Codigo_municipio'].str.replace(\"'\",\"\")\n",
    "df['Codigo_municipio'] = df['Codigo_municipio'].str.strip()\n",
    "df['Codigo_departamento'] = df['Codigo_departamento'].str.replace(\"'\",\"\")\n",
    "df['Codigo_departamento'] = df['Codigo_departamento'].str.strip()\n",
    "df['Cant_Kg'] = pd.to_numeric(df['Cant_Kg'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Enviamos la informacion a un archivo csv para ver como se est√° juntando el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11764957"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_path = '/mnt/d/Classes/Data visualization/Mapping data/Database/geo.db'\n",
    "conn = sqlite3.connect(user_path)\n",
    "df.to_sql('Fact', con=conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Iniciamos con la construccion de los mapas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.1 Establecemos las coordenadas de los centros mayoristas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Primero importamos las coordenadas de cada uno de los centros de acopia que se mencionan en la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordenadas_path = \"/home/npalaciosv/Catedra/Geoanalitycs/src/Data/Static/Coordenadas.csv\"\n",
    "df_coor = pd.read_csv(coordenadas_path,sep=\";\",encoding='utf-8')\n",
    "\n",
    "conn = sqlite3.connect(user_path)\n",
    "df_coor.to_sql('Coordenadas_mayoristas', con=conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Creamos el objeto mapa utilizando la libreria folium. Especificamos un punto central para que aparezca el mapa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = folium.Map(location=[4.922860659232988, -74.02580517889908], zoom_start=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Llamamos el icono de una plaza de mercado que escogimos para ponerlo como icono de marcacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "maps_path = '/home/npalaciosv/Catedra/Geoanalitycs/src/Graphs/'\n",
    "icon_path = '/home/npalaciosv/Catedra/Geoanalitycs/src/Icons/Mayorista.png'\n",
    "\n",
    "#\n",
    "lat = df_coor['Latitud'].to_list()\n",
    "lon = df_coor['Longitud'].to_list()\n",
    "fuente = df_coor['Mayorista'].to_list()\n",
    "coordenadas = list(zip(lat,lon,fuente))\n",
    "\n",
    "#\n",
    "for lat,lon,fuente in coordenadas:\n",
    "    folium.Marker(\n",
    "        [lat,lon],\n",
    "        popup=f'{fuente}',\n",
    "        icon=folium.CustomIcon(icon_image=icon_path,icon_size=(25,25))\n",
    "    ).add_to(map)\n",
    "map.save(maps_path+\"mapa.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.2 Establecemos las coordenadas de los municipios abastecedor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos la informacion que aparece en el archvio Clasificador_geografico.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir tipos de datos espec√≠ficos para las columnas\n",
    "column_types = {'C√≥digo Departamento': str, 'C√≥digo Municipio': str, 'C√≥digo Centro Poblado': str}\n",
    "\n",
    "geopath = '/home/npalaciosv/Catedra/Geoanalitycs/src/Data/Static/Clasificador_geografico.csv'\n",
    "df_geoclas = pd.read_csv(geopath,sep=\";\",encoding='utf-8', dtype=column_types)\n",
    "\n",
    "# Crear un diccionario para mapear los nombres de las columnas\n",
    "column_rename_map = {\n",
    "    'C√≥digo Departamento': 'Codigo_Departamento',\n",
    "    'C√≥digo Municipio': 'Codigo_Municipio',\n",
    "    'C√≥digo Centro Poblado': 'Codigo_Centro_Poblado'\n",
    "}\n",
    "\n",
    "# Renombrar las columnas usando el m√©todo rename\n",
    "df_geoclas = df_geoclas.rename(columns=column_rename_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geoclas = df_geoclas[['Codigo_Departamento','Codigo_Municipio','Longitud','Latitud']]\n",
    "df_geoclas = df_geoclas.drop_duplicates(subset=['Codigo_Municipio'])\n",
    "\n",
    "df_geoclas['Latitud'] = df_geoclas['Latitud'].str.replace(\",\",\".\")\n",
    "df_geoclas['Longitud'] = df_geoclas['Longitud'].str.replace(\",\",\".\")\n",
    "\n",
    "coordenadas_int_path = \"/home/npalaciosv/Catedra/Geoanalitycs/src/Data/Static/Coordenadas_internacionales.csv\"\n",
    "df_coor_int = pd.read_csv(coordenadas_int_path,sep=\";\",encoding='utf-8')\n",
    "\n",
    "# Convertir las columnas 'Latitud' y 'Longitud' a tipo float (double en pandas)\n",
    "df_coor_int['Latitud'] = df_coor_int['Latitud'].astype(float)\n",
    "df_coor_int['Longitud'] = df_coor_int['Longitud'].astype(float)\n",
    "\n",
    "list_coor_int = df_coor_int['Municipio'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear una sentencia SQL que nos traiga las ubicaciones de los proveedores que necesitamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1122"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(user_path)\n",
    "df_geoclas.to_sql('Clasificador_geografico', con=conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(user_path)\n",
    "cursor = conn.cursor()\n",
    "sentencia_sql = f'''\n",
    "                SELECT\n",
    "                    DISTINCT f.Codigo_Municipio,\n",
    "                    f.Municipio,\n",
    "                    cg.Latitud,\n",
    "                    cg.Longitud\n",
    "                FROM Fact f\n",
    "                LEFT JOIN Clasificador_geografico cg ON cg.Codigo_Municipio = f.Codigo_Municipio\n",
    "                    ;\n",
    "                '''\n",
    "\n",
    "cursor.execute(sentencia_sql)\n",
    "\n",
    "# Obtener los resultados de la consulta\n",
    "results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los resultados\n",
    "df_int = pd.DataFrame(results, columns=['Codigo_Municipio', 'Municipio', 'Latitud', 'Longitud'])\n",
    "\n",
    "for mun_int in list_coor_int:\n",
    "    df_int.loc[df_int['Municipio']==mun_int,'Latitud'] = df_coor_int.loc[df_coor_int['Municipio']==mun_int,'Latitud'].values\n",
    "    df_int.loc[df_int['Municipio']==mun_int,'Longitud'] = df_coor_int.loc[df_coor_int['Municipio']==mun_int,'Longitud'].values\n",
    "\n",
    "df_int = df_int.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "icon_path = '/home/npalaciosv/Catedra/Geoanalitycs/src/Icons/Productor.png'\n",
    "\n",
    "#\n",
    "lat = df_int['Latitud'].to_list()\n",
    "lon = df_int['Longitud'].to_list()\n",
    "municipio = df_int['Municipio'].to_list()\n",
    "coordenadas = list(zip(lat,lon,municipio))\n",
    "\n",
    "#\n",
    "for lat,lon,municipio in coordenadas:\n",
    "    folium.Marker(\n",
    "        [lat,lon],\n",
    "        popup=f'{municipio}',\n",
    "        icon=folium.CustomIcon(icon_image=icon_path,icon_size=(15,15))\n",
    "    ).add_to(map)\n",
    "map.save(maps_path+\"mapa.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.3 Coloreamos cada departamento de acuerdo a su capacidad productora**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "geopath = '/home/npalaciosv/Catedra/Geoanalitycs/src/Data/Static/colombia.geo.json'\n",
    "\n",
    "folium.GeoJson(geopath,\n",
    "               style_function= lambda feature : {\n",
    "                        'color': 'black',\n",
    "                        'weight': 2,\n",
    "                        'dashArray': '5, 5',\n",
    "                        'fillOpacity': 0.5,\n",
    "                        }\n",
    "               ).add_to(map)\n",
    "map.save(maps_path+\"mapa.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(user_path)\n",
    "cursor = conn.cursor()\n",
    "sentencia_sql = f'''\n",
    "                SELECT\n",
    "                    f.Codigo_departamento AS DPTO,\n",
    "                    SUM(f.Cant_Kg) AS Produccion\n",
    "                FROM Fact f\n",
    "                WHERE f.Codigo_departamento != 'n.a.'\n",
    "                GROUP BY f.Codigo_departamento\n",
    "                ORDER BY Produccion DESC\n",
    "                ;\n",
    "                '''\n",
    "\n",
    "cursor.execute(sentencia_sql)\n",
    "\n",
    "# Obtener los resultados de la consulta\n",
    "results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'DPTO': '25', 'Produccion': 6786107919.296},\n",
       " {'DPTO': '15', 'Produccion': 4400427211.527},\n",
       " {'DPTO': '05', 'Produccion': 3804643763.755},\n",
       " {'DPTO': '68', 'Produccion': 2730609255.394},\n",
       " {'DPTO': '76', 'Produccion': 2481002743.13},\n",
       " {'DPTO': '52', 'Produccion': 2423965237.539},\n",
       " {'DPTO': '50', 'Produccion': 2326006609.249},\n",
       " {'DPTO': '54', 'Produccion': 1492876634.912},\n",
       " {'DPTO': '11', 'Produccion': 1481709028.603},\n",
       " {'DPTO': '73', 'Produccion': 1290401140.915},\n",
       " {'DPTO': '63', 'Produccion': 872649277.478},\n",
       " {'DPTO': '23', 'Produccion': 820047330.802},\n",
       " {'DPTO': '41', 'Produccion': 774962367.911},\n",
       " {'DPTO': '17', 'Produccion': 708300483.243},\n",
       " {'DPTO': '81', 'Produccion': 526311244.624},\n",
       " {'DPTO': '08', 'Produccion': 510248712.027},\n",
       " {'DPTO': '47', 'Produccion': 452783227.959},\n",
       " {'DPTO': '19', 'Produccion': 450456382.505},\n",
       " {'DPTO': '66', 'Produccion': 412911803.823},\n",
       " {'DPTO': '13', 'Produccion': 293710118.93},\n",
       " {'DPTO': '85', 'Produccion': 261060042.626},\n",
       " {'DPTO': '20', 'Produccion': 191444027.288},\n",
       " {'DPTO': '00', 'Produccion': 178878142.966},\n",
       " {'DPTO': '70', 'Produccion': 90142760.349},\n",
       " {'DPTO': '18', 'Produccion': 85483678.836},\n",
       " {'DPTO': '44', 'Produccion': 55930437.602},\n",
       " {'DPTO': '86', 'Produccion': 30582653.549},\n",
       " {'DPTO': '27', 'Produccion': 30024953.03},\n",
       " {'DPTO': '95', 'Produccion': 18966891.128},\n",
       " {'DPTO': '91', 'Produccion': 8058411.7},\n",
       " {'DPTO': '99', 'Produccion': 1644849.3},\n",
       " {'DPTO': '94', 'Produccion': 225692.0},\n",
       " {'DPTO': '97', 'Produccion': 17065.0},\n",
       " {'DPTO': '88', 'Produccion': 7500.0}]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejecutar la consulta y cargar los resultados en un DataFrame\n",
    "df_temp = pd.DataFrame(results, columns=['DPTO', 'Produccion'])\n",
    "\n",
    "# Convertir el DataFrame a un diccionario\n",
    "temp_dict = df_temp.to_dict(orient='records')\n",
    "temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para asignar color basado en la producci√≥n\n",
    "def asignar_color(feature):\n",
    "\n",
    "    # Calcular el m√≠nimo y m√°ximo de las producciones\n",
    "    producciones = [item['Produccion'] for item in temp_dict]\n",
    "    produccion_minima = min(producciones)\n",
    "    produccion_maxima = max(producciones)*0.6\n",
    "\n",
    "    # Definir colores en la escala\n",
    "    color_minimo = 'red'\n",
    "    color_medio = 'orange'\n",
    "    color_maximo = 'green'\n",
    "\n",
    "    codigo_departamento = feature['properties'].get('DPTO')\n",
    "    print(codigo_departamento)\n",
    "    produccion = next((item['Produccion'] for item in temp_dict if item['DPTO'] == codigo_departamento), 0)  # Obtener la producci√≥n o 0 si no est√° definido\n",
    "\n",
    "    # Normalizar la producci√≥n entre 0 y 1\n",
    "    norm = mcolors.Normalize(vmin=produccion_minima, vmax=produccion_maxima)\n",
    "\n",
    "    # Crear una interpolaci√≥n lineal de colores\n",
    "    color_interp = mcolors.LinearSegmentedColormap.from_list('custom_map', [color_minimo, color_medio, color_maximo])\n",
    "\n",
    "    # Obtener el color seg√∫n la producci√≥n normalizada\n",
    "    color = mcolors.rgb2hex(color_interp(norm(produccion)))\n",
    "\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05\n",
      "05\n",
      "08\n",
      "11\n",
      "13\n",
      "15\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "23\n",
      "25\n",
      "27\n",
      "41\n",
      "44\n",
      "47\n",
      "50\n",
      "52\n",
      "54\n",
      "63\n",
      "66\n",
      "68\n",
      "70\n",
      "73\n",
      "76\n",
      "81\n",
      "85\n",
      "86\n",
      "91\n",
      "94\n",
      "95\n",
      "97\n",
      "99\n",
      "88\n",
      "05\n",
      "08\n",
      "11\n",
      "13\n",
      "15\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "23\n",
      "25\n",
      "27\n",
      "41\n",
      "44\n",
      "47\n",
      "50\n",
      "52\n",
      "54\n",
      "63\n",
      "66\n",
      "68\n",
      "70\n",
      "73\n",
      "76\n",
      "81\n",
      "85\n",
      "86\n",
      "91\n",
      "94\n",
      "95\n",
      "97\n",
      "99\n",
      "88\n",
      "05\n",
      "08\n",
      "11\n",
      "13\n",
      "15\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "23\n",
      "25\n",
      "27\n",
      "41\n",
      "44\n",
      "47\n",
      "50\n",
      "52\n",
      "54\n",
      "63\n",
      "66\n",
      "68\n",
      "70\n",
      "73\n",
      "76\n",
      "81\n",
      "85\n",
      "86\n",
      "91\n",
      "94\n",
      "95\n",
      "97\n",
      "99\n",
      "88\n",
      "05\n",
      "08\n",
      "11\n",
      "13\n",
      "15\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "23\n",
      "25\n",
      "27\n",
      "41\n",
      "44\n",
      "47\n",
      "50\n",
      "52\n",
      "54\n",
      "63\n",
      "66\n",
      "68\n",
      "70\n",
      "73\n",
      "76\n",
      "81\n",
      "85\n",
      "86\n",
      "91\n",
      "94\n",
      "95\n",
      "97\n",
      "99\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "folium.GeoJson(geopath,\n",
    "               style_function= lambda feature : {\n",
    "                        'fillColor':asignar_color(feature),\n",
    "                        'color': 'black',\n",
    "                        'weight': 2,\n",
    "                        'dashArray': '5, 5',\n",
    "                        'fillOpacity': 0.25,\n",
    "                        }\n",
    "               ).add_to(map)\n",
    "map.save(maps_path+\"mapa.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.3 Vinculamos los origenes productivos con las plazas mayoristas destino**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoanalitics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
